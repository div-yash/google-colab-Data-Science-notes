{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdOPptwtjY02rH3+ZGmwj7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/div-yash/google-colab-Data-Science-notes/blob/main/Feature_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extracting  : THe mapping from textual data to rea valued vectors .\n",
        "\n",
        "In ml , we will feed our model a lot of data , with which it can learn and find patterns in data and make predictions based on the data provided.\n",
        "\n",
        "Feature Vectors : Nummeric representation of textual data.\n",
        "\n",
        "Bag Of Words(BOW) : list of unique words in text corpus.\n",
        "\n",
        "Term Frequency -Inverse Document Frequrncy : (TF-IDF): To count the number of times each word appears in a  document .(list of all the words)\n",
        "(No. of times a word is repeated)\n",
        "eg: to predict whether a mail is spam mail  or normal mail , as spam mail conntains words like offers, discount, free.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fz1_LPLwnlT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tf-idf Vectorizer :\n",
        "\n",
        "Term frequency : no. of times a term t appears in a document / no. of terms in the document\n",
        "\n",
        "> this can tell us the important words in the document ."
      ],
      "metadata": {
        "id": "jr7AP-6Cp-l1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse Document Frequency : log(N/n)\n",
        "\n",
        "N\n",
        ": No. of words in document\n",
        "\n",
        "n\n",
        ": No. of times a term t has appeared in the document .\n",
        "\n",
        "\n",
        "> THe idf value of a rare word is high , whereas the idf of a frequent word is low ."
      ],
      "metadata": {
        "id": "orP0LMG6qa2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It means in a document there can be words like a , the , is etc.  which will be repeated a lot of times.\n",
        "\n",
        "we dont give significant focus to these words .\n",
        "\n",
        "Here we use IDF where if a word is of low frequency(i.e repeated a lot of times ), that word will have a small value\n",
        "\n"
      ],
      "metadata": {
        "id": "VheeNQRXr9xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> TF-IDF value of a term = TF * IDF"
      ],
      "metadata": {
        "id": "8TifNkAaswg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example :\n",
        "\n",
        "About the dataset\n",
        " : id: unique id for a news article\n",
        " : title: the title of a news article\n",
        " : author: author of the news article\n",
        " : text: the text of the article ;  could be incomplete\n",
        " : label: a label that marks whether the news article is real or fake\n",
        "\n",
        "1: Fake news\n",
        "\n",
        "0: real news"
      ],
      "metadata": {
        "id": "nnd0bqg5tcyl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7kDnXHrngRw"
      },
      "outputs": [],
      "source": [
        "# importing the dependencies :\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus  import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlHJPv4Gw9GY",
        "outputId": "76883477-4590-4dde-b899-b12db7e7d367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3qfiBV4VxFlb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}